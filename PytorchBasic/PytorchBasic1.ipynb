{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PytorchBasic1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMCD5z1uzjFBAf3jM9cEO/K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeongWoong-Hong/TA_session/blob/master/PytorchBasic/PytorchBasic1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxyOUd4Ozo61",
        "colab_type": "text"
      },
      "source": [
        "# **Pytorch Basic 1**\n",
        "\n",
        "Now, we will move to the new content, Pytorch.\n",
        "\n",
        "Pytorch is a Python-based computing package targeted those who need the power of GPUs and a deep learning research platform that provides much flexibility and speed.\n",
        "\n",
        "Pytorch is based on the Tensor data type. It is similar to matrix or Numpy's ndarray, one of the most used tool at Python, with the addition being that Tensors can also be used on a GPU to accelerate computing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fauKhr7gzcps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "x = torch.empty(5, 3)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Q2U7F2wTcgV",
        "colab_type": "text"
      },
      "source": [
        "We don't deal with the calculations of the methods for tensor data type here. It's quite simple and intuitive so please check url https://pytorch.org/tutorials/ if you want to learn more about the tensor data type.\n",
        "\n",
        "The most important reason that why we use Pytorch is the 'Autograd' package. The autograd package provides automatic differentiation for all operations on Tensors. It is a define-by-run framework, which means that differentiation is defined by how your code is run.\n",
        "\n",
        "Let's look at the example for understanding. This cell create the tensor type data that has 2 by 2 components 1s. `requires_grad=True` means it tracks all the operations on its tensor.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niyWszgFWzI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvRlCYq0W4pD",
        "colab_type": "text"
      },
      "source": [
        "Let's do some math operation whether it tracks well or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nX1ZgKGmY6bw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = x + 2\n",
        "print(y)\n",
        "\n",
        "z = y * y * 3\n",
        "print(z)\n",
        "\n",
        "out = z.mean()\n",
        "print(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awX9abAjavmM",
        "colab_type": "text"
      },
      "source": [
        "You can see that its output is operated well and its gradient function is recorded well also.\n",
        "\n",
        "The final value is a scalar value, `out`, and you can calculate its gradient in backward manner by using the `.backward()` method. It's just nothing but simple chain rule.\n",
        "\n",
        "You can get the partial differentiation with the attribute `.grad`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qj8rqa4BbpDN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out.backward()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewsq-XFzb5tc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(x.grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xChQh2uncku2",
        "colab_type": "text"
      },
      "source": [
        "Let's look at their calculation process. Let's call the `out` Tensor \"$o$\". In the above calculation, $ o=\\frac{1}{4}\\sum_{i}z_i\\ $, $ z_i=3y_i^2 $ and $ y_i = x_i+2 $. Therefore, $\\frac{\\partial o}{\\partial x_i}=\\frac{\\partial o}{\\partial z_i}\\frac{\\partial z_i}{\\partial y_i}\\frac{\\partial y_i}{\\partial x_i}\\ =\\frac{1}{4}\\times6y_i\\times1=\\frac{3}{2}(x_i+2)$, hence $\\left.\\frac{\\partial o}{\\partial x_i}\\right|_{x_i=1}=4.5$.\n",
        "\n",
        "This is how to the tensor type calculates the gradient in backward manner. Now we will move on to how to use Pytorch to handle the real problem."
      ]
    }
  ]
}